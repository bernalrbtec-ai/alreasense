# ğŸš€ Deploy Redis Streams - Flow Chat

## ğŸ“‹ Resumo

MigraÃ§Ã£o do sistema de envio de mensagens do chat de **Redis Lists (LPUSH/BRPOP)** para **Redis Streams** com Consumer Groups.

### âœ… BenefÃ­cios

- **Garantia de entrega**: ACK automÃ¡tico, mensagens nÃ£o se perdem se worker cair
- **Escalabilidade**: MÃºltiplos workers podem processar em paralelo
- **Reprocessamento**: Mensagens travadas sÃ£o automaticamente recuperadas
- **Dead-Letter Queue**: Mensagens que falham apÃ³s N tentativas vÃ£o para DLQ
- **MÃ©tricas**: Monitoramento completo via endpoint `/api/chat/reactions/queues/status/`

---

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. VariÃ¡veis de Ambiente (Railway)

Adicione no serviÃ§o **backend** do Railway:

```bash
# Redis exclusivo para Streams do chat
CHAT_STREAM_REDIS_URL=redis://default:oIdxJhhfoMZPtxSTAHytqNkQWBLpyQDX@redis.railway.internal:6379/3
CHAT_STREAM_REDIS_DB=3
CHAT_STREAM_REDIS_PREFIX=chat:stream:

# Streams que vamos criar
CHAT_STREAM_SEND_NAME=chat:stream:send_message
CHAT_STREAM_MARK_READ_NAME=chat:stream:mark_as_read
CHAT_STREAM_DLQ_NAME=chat:stream:dead_letter

# ConfiguraÃ§Ã£o do consumer group
CHAT_STREAM_CONSUMER_GROUP=chat_send_workers
CHAT_STREAM_MAXLEN=5000
CHAT_STREAM_DLQ_MAXLEN=2000
CHAT_STREAM_MAX_RETRIES=5
CHAT_STREAM_RECLAIM_IDLE_MS=60000
```

### 2. Criar Novo ServiÃ§o no Railway

**Nome**: `chat-stream-worker`  
**Build**: Mesmo Dockerfile do backend  
**Start Command**: 
```bash
python manage.py start_chat_stream_worker --send-workers 3 --mark-workers 2
```

**VariÃ¡veis de Ambiente**: Mesmas do backend (copiar todas)

**Recursos**: 
- CPU: 512 MB (mÃ­nimo)
- RAM: 512 MB (mÃ­nimo)
- Pode escalar horizontalmente (mÃºltiplas rÃ©plicas)

---

## ğŸ¯ Arquitetura

### Fluxo de Envio

```
API Request â†’ tasks.py (send_message_to_evolution.delay)
    â†“
redis_streams.py (enqueue_send_message_async)
    â†“
Redis Stream: chat:stream:send_message
    â†“
stream_consumer.py (process_send_message_worker)
    â†“
tasks.py (handle_send_message)
    â†“
Evolution API â†’ WebSocket Broadcast
```

### Consumer Groups

- **Grupo**: `chat_send_workers`
- **Consumers**: `worker-{hostname}-{pid}-{id}` (Ãºnico por instÃ¢ncia)
- **Streams**:
  - `chat:stream:send_message` (envio de mensagens)
  - `chat:stream:mark_as_read` (read receipts)

### Dead-Letter Queue

- **Stream**: `chat:stream:dead_letter`
- **Trigger**: ApÃ³s `CHAT_STREAM_MAX_RETRIES` (padrÃ£o: 5) tentativas falhadas
- **ConteÃºdo**: Payload original + metadata de erro + retry_count

---

## ğŸ“Š Monitoramento

### Endpoint de MÃ©tricas

```bash
GET /api/chat/reactions/queues/status/
```

**Resposta**:
```json
{
  "metrics": {
    "stream_metrics": {
      "send_message": {
        "length": 10,
        "pending": 2,
        "consumers": 3
      },
      "mark_as_read": {
        "length": 5,
        "pending": 0,
        "consumers": 2
      },
      "dead_letter": {
        "length": 1
      }
    }
  },
  "alerts": [
    "âš ï¸ Stream send_message tem 1500 mensagens (acima de 1000)"
  ],
  "timestamp": "2025-11-06T..."
}
```

### Logs Importantes

- `âœ… [CHAT STREAM] Mensagem enfileirada`: Sucesso ao adicionar na stream
- `ğŸ“¥ [CHAT STREAM] Processando send_message`: Worker pegou mensagem
- `âœ… [CHAT STREAM] send_message concluÃ­da`: Envio bem-sucedido
- `âš ï¸ [CHAT STREAM] Mensagens recuperadas`: Reprocessamento automÃ¡tico
- `âŒ [CHAT STREAM] Movido para DLQ`: Falha apÃ³s N tentativas

---

## ğŸ” Troubleshooting

### Worker nÃ£o processa mensagens

1. **Verificar conexÃ£o Redis**:
   ```bash
   redis-cli -h redis.railway.internal -p 6379 -a oIdxJhhfoMZPtxSTAHytqNkQWBLpyQDX
   > SELECT 3
   > XINFO GROUPS chat:stream:send_message
   ```

2. **Verificar se grupo existe**:
   ```bash
   > XGROUP CREATE chat:stream:send_message chat_send_workers $ MKSTREAM
   ```

3. **Verificar mensagens pendentes**:
   ```bash
   > XPENDING chat:stream:send_message chat_send_workers
   ```

### Mensagens travadas

O worker automaticamente recupera mensagens pendentes apÃ³s 60s (`CHAT_STREAM_RECLAIM_IDLE_MS`).

Para forÃ§ar recuperaÃ§Ã£o manual:
```bash
> XAUTOCLAIM chat:stream:send_message chat_send_workers worker-1 60000 0-0 COUNT 100
```

### Dead-Letter Queue cheia

1. **Inspecionar mensagens**:
   ```bash
   > XRANGE chat:stream:dead_letter - + COUNT 10
   ```

2. **Reprocessar manualmente** (se necessÃ¡rio):
   - Extrair payload da DLQ
   - Re-enfileirar via API ou diretamente na stream

---

## ğŸš¦ MigraÃ§Ã£o (Rollback se necessÃ¡rio)

### Voltar para Redis Lists

1. **Parar worker de streams**:
   ```bash
   # No Railway: Desabilitar serviÃ§o chat-stream-worker
   ```

2. **Reverter cÃ³digo**:
   ```bash
   git revert <commit-hash>
   ```

3. **Reiniciar consumer antigo**:
   ```bash
   python manage.py start_chat_consumer --queues send_message mark_as_read
   ```

### CoexistÃªncia

Durante migraÃ§Ã£o, ambos podem rodar simultaneamente:
- **Streams**: Novo worker (`start_chat_stream_worker`)
- **Lists**: Consumer antigo (`start_chat_consumer`)

**âš ï¸ CUIDADO**: NÃ£o rodar ambos processando as mesmas filas ao mesmo tempo (duplicaÃ§Ã£o).

---

## ğŸ“ˆ Escalabilidade

### Aumentar Workers

**Railway**: Aumentar nÃºmero de rÃ©plicas do serviÃ§o `chat-stream-worker`

**Ou via variÃ¡vel**:
```bash
CHAT_STREAM_SEND_WORKERS=5  # Por instÃ¢ncia
CHAT_STREAM_MARK_WORKERS=3
```

### Performance Esperada

- **LatÃªncia**: 2-6ms (enfileiramento)
- **Throughput**: ~100-500 mensagens/segundo por worker
- **Escalabilidade**: Linear (mais workers = mais throughput)

---

## âœ… Checklist de Deploy

- [ ] VariÃ¡veis de ambiente configuradas no Railway
- [ ] Novo serviÃ§o `chat-stream-worker` criado
- [ ] Worker iniciado e processando mensagens
- [ ] MÃ©tricas disponÃ­veis em `/api/chat/reactions/queues/status/`
- [ ] Logs mostrando processamento normal
- [ ] Teste de envio de mensagem funcionando
- [ ] Teste de read receipt funcionando
- [ ] Verificar DLQ (deve estar vazia inicialmente)

---

## ğŸ‰ Pronto!

O sistema agora usa Redis Streams para envio de mensagens, com garantias de entrega e escalabilidade horizontal.

**PrÃ³ximos passos**:
- Monitorar mÃ©tricas por alguns dias
- Ajustar nÃºmero de workers conforme carga
- Implementar alertas automÃ¡ticos (se necessÃ¡rio)

