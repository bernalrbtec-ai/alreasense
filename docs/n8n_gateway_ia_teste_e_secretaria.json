{
  "name": "Sense - Gateway IA (teste e Secretária)",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Payload enviado pelo Sense: pode vir em $input.first().json ou aninhado em .body\nconst raw = $input.first().json;\nconst body = raw.body && typeof raw.body === 'object' ? raw.body : raw;\n\nconst promptFromBody = body.prompt || (body.metadata && body.metadata.prompt) || '';\nconst systemPrompt = (promptFromBody && String(promptFromBody).trim()) ? String(promptFromBody).trim() : 'Você é um assistente prestativo.';\nconst knowledgeItems = Array.isArray(body.knowledge_items) ? body.knowledge_items : [];\nconst context = knowledgeItems.map(i => `## ${i.title || 'Documento'}\\n${i.content || ''}`).join('\\n\\n');\nconst userMessage = (body.message && body.message.content) ? String(body.message.content) : '';\nconst fullPrompt = [\n  systemPrompt,\n  context ? `Contexto para consulta:\\n${context}` : '',\n  userMessage ? `Mensagem do usuário: ${userMessage}` : ''\n].filter(Boolean).join('\\n\\n');\n\nconst model = (body.metadata && body.metadata.model) ? String(body.metadata.model).trim() : (body.model ? String(body.model).trim() : 'llama3.2');\n\nreturn [{ json: { fullPrompt, model, knowledgeItemsCount: knowledgeItems.length } }];"
      },
      "id": "189a9d0a-a51e-46cd-a0d5-f76895ff2c73",
      "name": "Montar prompt e modelo",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-416, -320]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=http://172.16.20.66:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { model: $json.model, prompt: $json.fullPrompt, stream: false } }}",
        "options": {}
      },
      "id": "8035cc92-393e-4ca2-8477-941daaf6f803",
      "name": "Chamar Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-208, -320],
      "notesInFlow": true,
      "notes": "Use sua credencial Ollama/API aqui e ajuste a URL (ex.: base da credencial + /api/generate)"
    },
    {
      "parameters": {
        "jsCode": "// Resposta do Ollama: { response, model, ... }\nconst ollama = $input.first().json;\nconst prev = $('Montar prompt e modelo').first().json;\nconst replyText = (ollama.response && String(ollama.response).trim()) ? String(ollama.response).trim() : '(Sem resposta do modelo.)';\n\nreturn [{\n  json: {\n    reply_text: replyText,\n    status: 'success',\n    meta: {\n      model: ollama.model || prev.model,\n      latency_ms: ollama.eval_duration ? Math.round(ollama.eval_duration * 1000) : 0,\n      rag_hits: prev.knowledgeItemsCount || 0\n    }\n  }\n}];\n"
      },
      "id": "3e8dc5ec-cb5c-4e9e-9042-c38c557a8383",
      "name": "Formatar resposta para o Sense",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [16, -320]
    },
    {
      "parameters": { "options": {} },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.5,
      "position": [768, 144],
      "id": "a7a76380-14f0-4496-a5d3-aa361715524c",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "gateway-ia",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "5066274b-066d-41a2-ba0e-0b9a58a5b8b1",
      "name": "Webhook Sense IA",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [-592, 64],
      "webhookId": "sense-ia-gateway"
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict" },
          "conditions": [{ "id": "cond-chat", "leftValue": "={{ $json.useChat }}", "rightValue": true, "operator": { "type": "boolean", "operation": "equals" } }],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "53011afe-acde-44b4-960c-2676961a9cfe",
      "name": "Usar chat com histórico?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-160, 144]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://172.16.20.66:11434/api/chat",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { model: $json.model, messages: $json.messages, stream: false } }}",
        "options": {}
      },
      "id": "9dae62ff-ae67-4f81-afb0-6682fe75c826",
      "name": "Chamar Ollama (chat)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [64, 32],
      "notesInFlow": true,
      "notes": "Use sua credencial Ollama aqui e ajuste a URL (ex.: base da credencial + /api/chat)"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://172.16.20.66:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { model: $json.model, prompt: $json.fullPrompt, stream: false } }}",
        "options": {}
      },
      "id": "b48d51e2-1fd4-470c-8b35-fbe30ed10db3",
      "name": "Chamar Ollama (generate)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [64, 240],
      "notesInFlow": true,
      "notes": "Use sua credencial Ollama aqui e ajuste a URL (ex.: base da credencial + /api/generate)"
    },
    {
      "parameters": {},
      "id": "10f1c6fd-4270-4fd8-91cc-f648ed8c0feb",
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [288, 144]
    },
    {
      "parameters": {
        "jsCode": "const raw = $input.first().json;\nconst body = raw.body && typeof raw.body === 'object' ? raw.body : raw;\n\nconst isSecretary = (body.action === 'secretary' || body.agent_type === 'secretary');\nconst promptFromBody = body.prompt || (body.metadata && body.metadata.prompt) || '';\nconst defaultSecretaryPrompt = 'Você é a secretária virtual da empresa. Use o contexto abaixo (dados da empresa, histórico do contato e departamentos) para responder de forma cordial e objetiva. Se o assunto for claramente de um departamento específico, ao final da resposta você pode indicar em uma linha: SUGERIR_DEPARTAMENTO: <uuid do departamento> e RESUMO_PARA_DEPARTAMENTO: <resumo em uma frase>. Caso contrário, apenas responda normalmente.';\nconst systemPrompt = (promptFromBody && String(promptFromBody).trim()) ? String(promptFromBody).trim() : (isSecretary ? defaultSecretaryPrompt : 'Você é um assistente prestativo.');\n\nconst knowledgeItems = Array.isArray(body.knowledge_items) ? body.knowledge_items : [];\nconst contextParts = [knowledgeItems.map(i => '## ' + (i.title || 'Documento') + '\\n' + (i.content || '')).join('\\n\\n')];\nif (isSecretary && Array.isArray(body.memory_items) && body.memory_items.length > 0) {\n  contextParts.push('Histórico relevante do contato:\\n' + body.memory_items.map(m => '- ' + (m.content || '')).join('\\n'));\n}\nif (isSecretary && Array.isArray(body.departments) && body.departments.length > 0) {\n  contextParts.push('Departamentos para encaminhamento (id, nome, palavras-chave):\\n' + body.departments.map(d => '- ' + d.id + ': ' + d.name + ' (' + (d.routing_keywords || []).join(', ') + ')').join('\\n'));\n}\nconst context = contextParts.filter(Boolean).join('\\n\\n');\nconst model = (body.metadata && body.metadata.model) ? String(body.metadata.model).trim() : (body.model ? String(body.model).trim() : 'llama3.2');\nconst knowledgeItemsCount = knowledgeItems.length;\n\nconst useChat = Array.isArray(body.messages) && body.messages.length > 0;\n\nif (useChat) {\n  const systemContent = [systemPrompt, context ? 'Contexto para consulta:\\n' + context : ''].filter(Boolean).join('\\n\\n');\n  const messages = [\n    { role: 'system', content: systemContent },\n    ...body.messages.map(m => ({ role: (m.role || (m.direction === 'incoming' ? 'user' : 'assistant')).toLowerCase(), content: String(m.content || '') }))\n  ];\n  return [{ json: { useChat: true, model, messages, knowledgeItemsCount, isSecretary } }];\n}\n\nconst userMessage = (body.message && body.message.content) ? String(body.message.content) : '';\nconst fullPrompt = [\n  systemPrompt,\n  context ? 'Contexto para consulta:\\n' + context : '',\n  userMessage ? 'Mensagem do usuário: ' + userMessage : ''\n].filter(Boolean).join('\\n\\n');\n\nreturn [{ json: { useChat: false, model, fullPrompt, knowledgeItemsCount, isSecretary } }];\n"
      },
      "id": "571971c3-f582-4785-bd93-c71d6a46a05c",
      "name": "Montar prompt e modelo1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-384, 144]
    },
    {
      "parameters": {
        "jsCode": "const ollama = $input.first().json;\nconst prev = $('Montar prompt e modelo1').first().json;\nlet replyText = (ollama.message && ollama.message.content)\n  ? String(ollama.message.content).trim()\n  : (ollama.response && String(ollama.response).trim())\n    ? String(ollama.response).trim()\n    : '(Sem resposta do modelo.)';\nconst evalDurationNs = ollama.eval_duration || 0;\nconst latencyMs = evalDurationNs > 0 ? Math.round(evalDurationNs / 1e6) : 0;\n\nconst out = {\n  reply_text: replyText,\n  status: 'success',\n  meta: {\n    model: ollama.model || prev.model,\n    latency_ms: latencyMs,\n    rag_hits: prev.knowledgeItemsCount || 0\n  }\n};\n\nif (prev.isSecretary && replyText) {\n  const lines = replyText.split('\\n');\n  let suggested_department_id = null;\n  let summary_for_department = null;\n  for (const line of lines) {\n    const depMatch = line.trim().match(/SUGERIR_DEPARTAMENTO:\\s*([a-f0-9-]{36})/i);\n    const sumMatch = line.trim().match(/RESUMO_PARA_DEPARTAMENTO:\\s*(.+)/i);\n    if (depMatch) suggested_department_id = depMatch[1].trim();\n    if (sumMatch) summary_for_department = sumMatch[1].trim().slice(0, 2000);\n  }\n  const cleanLines = lines.filter(l => !l.trim().match(/SUGERIR_DEPARTAMENTO:/i) && !l.trim().match(/RESUMO_PARA_DEPARTAMENTO:/i));\n  out.reply_text = cleanLines.join('\\n').replace(/\\n\\n+/g, '\\n\\n').trim();\n  if (suggested_department_id) out.suggested_department_id = suggested_department_id;\n  if (summary_for_department) out.summary_for_department = summary_for_department;\n}\n\nreturn [{ json: out }];\n"
      },
      "id": "8a79f9f4-e0d6-41f2-b913-07ca8587a2a7",
      "name": "Formatar resposta para o Sense1",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [512, 144]
    }
  ],
  "connections": {
    "Montar prompt e modelo": { "main": [[{ "node": "Chamar Ollama", "type": "main", "index": 0 }]] },
    "Chamar Ollama": { "main": [[{ "node": "Formatar resposta para o Sense", "type": "main", "index": 0 }]] },
    "Formatar resposta para o Sense": { "main": [[]] },
    "Webhook Sense IA": { "main": [[{ "node": "Montar prompt e modelo1", "type": "main", "index": 0 }]] },
    "Usar chat com histórico?": { "main": [[{ "node": "Chamar Ollama (chat)", "type": "main", "index": 0 }], [{ "node": "Chamar Ollama (generate)", "type": "main", "index": 0 }]] },
    "Chamar Ollama (chat)": { "main": [[{ "node": "Merge", "type": "main", "index": 0 }]] },
    "Chamar Ollama (generate)": { "main": [[{ "node": "Merge", "type": "main", "index": 1 }]] },
    "Merge": { "main": [[{ "node": "Formatar resposta para o Sense1", "type": "main", "index": 0 }]] },
    "Montar prompt e modelo1": { "main": [[{ "node": "Usar chat com histórico?", "type": "main", "index": 0 }]] },
    "Formatar resposta para o Sense1": { "main": [[{ "node": "Respond to Webhook", "type": "main", "index": 0 }]] }
  },
  "active": false,
  "settings": { "executionOrder": "v1" },
  "meta": { "templateCredsSetupCompleted": true }
}
