Vis√£o geral

Backend: Django 5 + Django REST Framework (DRF) + Django Channels (tempo real) + Celery (jobs)

Frontend: React + Vite + Tailwind + shadcn/ui

DB: PostgreSQL 15/16 + pgvector (coluna vector p/ embeddings)

Multi-tenant: por linha (tenant_id em todas as tabelas) + permiss√µes por escopo

IA: seu Qwen/Ollama local via n8n (MCP/HTTP)

Ingest√£o WhatsApp: Evolution API via WebSocket (cliente Python ass√≠ncrono)

Deploy: Railway (Django/React + Postgres). No Postgres do Railway: CREATE EXTENSION IF NOT EXISTS vector;

Estrutura de pastas (monorepo)
/evosense
  /backend
    manage.py
    evosense/settings.py
    evosense/asgi.py
    evosense/celery.py
    /apps
      /tenancy
      /authn
      /connections
      /messages
      /ai
      /billing
      /experiments
    /ingestion
      evolution_ws.py
    /common
      utils.py, permissions.py
    requirements.txt
  /frontend
    (React + Vite)
  docker-compose.yml
  README.md

Banco + pgvector
Extens√£o e √≠ndice

No Railway (ou migration inicial):

CREATE EXTENSION IF NOT EXISTS vector;
-- 768 dims (ajuste ao seu encoder)
ALTER TABLE messages_message ADD COLUMN embedding vector(768);
CREATE INDEX IF NOT EXISTS idx_message_embedding
  ON messages_message USING ivfflat (embedding vector_cosine) WITH (lists = 100);


Dica: se o encoder for Qwen-mini-embeddings (por ex.), ajuste 768/1024 conforme o modelo.

Modelos principais (Django)
# apps/tenancy/models.py
import uuid
from django.db import models

class Tenant(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=160)
    plan = models.CharField(max_length=32, default="starter")  # starter|pro|scale|enterprise
    next_billing_date = models.DateField(null=True, blank=True)
    status = models.CharField(max_length=16, default="active")  # active|suspended
    created_at = models.DateTimeField(auto_now_add=True)

# apps/authn/models.py
from django.contrib.auth.models import AbstractUser
from django.db import models
from apps.tenancy.models import Tenant

class User(AbstractUser):
    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE, related_name="users")
    role = models.CharField(max_length=16, default="operator")  # admin|operator

# apps/connections/models.py
from django.db import models
from apps.tenancy.models import Tenant

class EvolutionConnection(models.Model):
    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE, related_name="connections")
    name = models.CharField(max_length=80)
    evo_ws_url = models.URLField()
    evo_token = models.CharField(max_length=255)  # mantenha criptografado/Hashicorp/Vault se poss√≠vel
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)

# apps/messages/models.py
from django.db import models
from django.contrib.postgres.indexes import GinIndex
from apps.tenancy.models import Tenant

class Message(models.Model):
    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE, related_name="messages")
    connection = models.ForeignKey('connections.EvolutionConnection', on_delete=models.SET_NULL, null=True)
    chat_id = models.CharField(max_length=128, db_index=True)
    sender = models.CharField(max_length=64)    # hash do n√∫mero/ID
    text = models.TextField()
    created_at = models.DateTimeField(db_index=True)
    # resultados IA
    sentiment = models.FloatField(null=True, blank=True)     # -1..1
    emotion = models.CharField(max_length=40, null=True, blank=True)
    satisfaction = models.IntegerField(null=True, blank=True) # 0..100
    tone = models.CharField(max_length=40, null=True, blank=True)
    summary = models.CharField(max_length=200, null=True, blank=True)
    # pgvector
    embedding = models.BinaryField(null=True, blank=True)  # DRF/Prisma vs vector: use adapter no DAO (ver abaixo)

    class Meta:
        indexes = [GinIndex(fields=['text'])]  # full-text fallback


Observa√ß√£o pgvector em Django: n√£o h√° campo nativo ‚ÄúVector‚Äù no core. Duas abordagens:

Usar SQL cru para INSERT/UPDATE da coluna vector, convertendo list[float] ‚Üí vector.

Usar um custom field/adapter. A pr√°tica mais simples √© manter embedding como list[float] em mem√≥ria e escrever com cursor.execute("UPDATE ... SET embedding = %s::vector", [pgvector_str]).

DAO helper:

# apps/messages/dao.py
from django.db import connection

def write_embedding(message_id: int, emb: list[float]):
    vec = "[" + ",".join(f"{x:.6f}" for x in emb) + "]"
    with connection.cursor() as cur:
        cur.execute("UPDATE messages_message SET embedding = %s::vector WHERE id = %s", [vec, message_id])

def semantic_search(tenant_id, query_emb, limit=20):
    vec = "[" + ",".join(f"{x:.6f}" for x in query_emb) + "]"
    with connection.cursor() as cur:
        cur.execute("""
            SELECT id, text, sentiment, satisfaction
            FROM messages_message
            WHERE tenant_id = %s
            ORDER BY embedding <-> %s::vector
            LIMIT %s
        """, [str(tenant_id), vec, limit])
        rows = cur.fetchall()
    return rows

Experimentos de prompt/modelo
# apps/experiments/models.py
from django.db import models
from apps.messages.models import Message
from apps.tenancy.models import Tenant

class PromptTemplate(models.Model):
    version = models.CharField(max_length=64, unique=True)
    body = models.TextField()  # texto do prompt
    created_at = models.DateTimeField(auto_now_add=True)

class Inference(models.Model):
    tenant = models.ForeignKey(Tenant, on_delete=models.CASCADE)
    message = models.ForeignKey(Message, on_delete=models.CASCADE, related_name="inferences")
    model_name = models.CharField(max_length=64)         # qwen-X, ollama-qwen2...
    prompt_version = models.CharField(max_length=64)
    template_hash = models.CharField(max_length=64)
    latency_ms = models.IntegerField()
    sentiment = models.FloatField()
    emotion = models.CharField(max_length=40)
    satisfaction = models.IntegerField()
    is_shadow = models.BooleanField(default=False)
    run_id = models.CharField(max_length=64, db_index=True)  # experimento
    created_at = models.DateTimeField(auto_now_add=True)

API (DRF) ‚Äî endpoints

POST /api/auth/login ‚Äî JWT

GET /api/me

GET /api/tenants/:id/metrics ‚Äî KPIs (m√©dias, volumes, p95 lat√™ncia)

GET /api/messages?tenant_id=&chat_id=&q= ‚Äî pagina√ß√£o + busca full-text

POST /api/messages/semantic-search ‚Äî recebe query, retorna top-K (usa pgvector)

GET /api/connections / POST /api/connections ‚Äî gerenciar Evolution

POST /api/experiments/replay ‚Äî dispara backfill ass√≠ncrono (Celery) com prompt_version

GET /api/prompts / POST /api/prompts ‚Äî registrar vers√µes de prompt

POST /api/ai/analyze ‚Äî for√ßa an√°lise (debug/admin)

POST /api/webhooks/stripe ‚Äî billing

POST /api/webhooks/evolution ‚Äî (opcional) fallback http

Exemplo View (semantic search):

# apps/messages/views.py
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.permissions import IsAuthenticated
from apps.messages.dao import semantic_search
from apps.ai.embeddings import embed_text

class SemanticSearchView(APIView):
    permission_classes = [IsAuthenticated]
    def post(self, request):
        tenant_id = request.user.tenant_id
        query = request.data.get("query", "")
        emb = embed_text(query)  # chama seu encoder local via n8n/HTTP
        rows = semantic_search(tenant_id, emb, limit=20)
        return Response({"results": [
            {"id": r[0], "text": r[1], "sentiment": r[2], "satisfaction": r[3]}
            for r in rows
        ]})

Ingest√£o Evolution (WebSocket) ‚Äî Python ass√≠ncrono
# ingestion/evolution_ws.py
import asyncio, json, websockets, datetime
from django.utils import timezone
from apps.messages.models import Message
from apps.ai.tasks import analyze_message_async

async def listen_connection(conn):
    headers = [("Authorization", f"Bearer {conn.evo_token}")]
    async with websockets.connect(conn.evo_ws_url, extra_headers=headers) as ws:
        async for raw in ws:
            evt = json.loads(raw)
            if evt.get("type") == "message":
                msg = Message.objects.create(
                    tenant=conn.tenant,
                    connection=conn,
                    chat_id=evt["chatId"],
                    sender=evt["from"],
                    text=evt["body"],
                    created_at=timezone.now()
                )
                analyze_message_async.delay(str(conn.tenant_id), msg.id)  # Celery

async def main():
    from apps.connections.models import EvolutionConnection
    conns = EvolutionConnection.objects.filter(is_active=True)
    await asyncio.gather(*(listen_connection(c) for c in conns))

# rode em um worker separados (daphne/asgi + esse loop em um process)

Celery (jobs IA e backfill)
# evosense/celery.py
import os
from celery import Celery
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'evosense.settings')
app = Celery('evosense')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

# apps/ai/tasks.py
import time, requests
from celery import shared_task
from django.conf import settings
from apps.messages.models import Message
from apps.messages.dao import write_embedding
from apps.experiments.models import Inference, PromptTemplate
from apps.ai.embeddings import embed_text  # seu cliente p/ Qwen/Ollama via n8n

@shared_task
def analyze_message_async(tenant_id, message_id, prompt_version=None, is_shadow=False, run_id="prod"):
    msg = Message.objects.get(id=message_id)
    template = PromptTemplate.objects.order_by('-created_at').first() if not prompt_version \
        else PromptTemplate.objects.get(version=prompt_version)

    payload = {
        "tenant_id": tenant_id,
        "message": msg.text,
        "context": {"chat_id": msg.chat_id, "sender": msg.sender},
        "prompt_version": template.version
    }
    t0 = time.time()
    r = requests.post(settings.N8N_AI_WEBHOOK, json=payload, timeout=3.0)
    r.raise_for_status()
    data = r.json()
    latency = int((time.time() - t0) * 1000)

    # persistir no Message (apenas campe√£o) e sempre na tabela de Inference
    if not is_shadow:
        msg.sentiment = data["sentiment"]
        msg.emotion = data["emotion"]
        msg.satisfaction = data["satisfaction"]
        msg.tone = data.get("tone")
        msg.summary = data.get("summary")
        msg.save(update_fields=["sentiment","emotion","satisfaction","tone","summary"])

    # embedding (opcional por plano)
    try:
        emb = embed_text(msg.text)
        write_embedding(msg.id, emb)
    except Exception:
        pass

    Inference.objects.create(
        tenant_id=tenant_id, message=msg, model_name=data.get("model","qwen-local"),
        prompt_version=template.version, template_hash="...", latency_ms=latency,
        sentiment=data["sentiment"], emotion=data["emotion"],
        satisfaction=data["satisfaction"], is_shadow=is_shadow, run_id=run_id
    )


Backfill (replay com outro prompt):

@shared_task
def replay_window(tenant_id, start_iso, end_iso, prompt_version, run_id):
    qs = Message.objects.filter(tenant_id=tenant_id, created_at__range=[start_iso, end_iso]).values_list("id", flat=True)
    for mid in qs:
        analyze_message_async.delay(tenant_id, mid, prompt_version=prompt_version, is_shadow=True, run_id=run_id)

Channels (tempo real)

ASGI (Daphne/Uvicorn), Channels + Redis (Railway tem Redis opcional).

Emita eventos ‚Äúmessage_analyzed‚Äù para salas por tenant_id/chat_id.

routing.py

from django.urls import re_path
from .consumers import TenantConsumer

websocket_urlpatterns = [
    re_path(r'ws/tenant/(?P<tenant_id>[^/]+)/$', TenantConsumer.as_asgi()),
]


consumers.py

from channels.generic.websocket import AsyncJsonWebsocketConsumer

class TenantConsumer(AsyncJsonWebsocketConsumer):
    async def connect(self):
        self.tenant_id = self.scope['url_route']['kwargs']['tenant_id']
        self.group = f"tenant_{self.tenant_id}"
        await self.channel_layer.group_add(self.group, self.channel_name)
        await self.accept()

    async def disconnect(self, code):
        await self.channel_layer.group_discard(self.group, self.channel_name)

    async def message_analyzed(self, event):
        await self.send_json(event["payload"])


No analyze_message_async, ao finalizar:

from asgiref.sync import async_to_sync
from channels.layers import get_channel_layer
layer = get_channel_layer()
async_to_sync(layer.group_send)(f"tenant_{tenant_id}", {
  "type": "message_analyzed",
  "payload": {"message_id": msg.id, "sentiment": msg.sentiment, "satisfaction": msg.satisfaction}
})

Frontend (React)

P√°ginas: Login, Dashboard, Conversas, Conex√µes, Experimentos, Billing

Tempo real: conectar no ws://<backend>/ws/tenant/<tenant_id>/ e atualizar cards

Busca sem√¢ntica: endpoint /api/messages/semantic-search

Ex. hook WS:

import { useEffect, useRef } from 'react';

export function useTenantWS(tenantId: string) {
  const ref = useRef<WebSocket | null>(null);
  useEffect(() => {
    const ws = new WebSocket(`${import.meta.env.VITE_WS_BASE}/ws/tenant/${tenantId}/`);
    ref.current = ws;
    ws.onmessage = (e) => {
      const evt = JSON.parse(e.data);
      // atualizar store com evt.payload
    };
    return () => ws.close();
  }, [tenantId]);
}

Docker Compose (local)
version: "3.9"
services:
  db:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: evosense
    ports: ["5432:5432"]
  redis:
    image: redis:7
    ports: ["6379:6379"]
  backend:
    build: ./backend
    env_file: ./backend/.env
    depends_on: [db, redis]
    ports: ["8000:8000"]
  frontend:
    build: ./frontend
    ports: ["5173:5173"]


No Railway, use servi√ßo Postgres nativo (rodar CREATE EXTENSION vector; uma vez), + app Django (executar python manage.py migrate).

Boas pr√°ticas multi-tenant

QuerySet base sempre filtrando por request.user.tenant_id (permission classes/filters DRF).

Plan limits: middleware ou service central (ex.: ‚Äúmax connections por plano‚Äù).

Mascaramento de PII (regex) antes de enviar ao n8n/IA.

Audit log por tenant (altera√ß√µes de conex√£o, plano, export).

Por que pgvector aqui ajuda?

Busca sem√¢ntica (encontrar mensagens parecidas com uma reclama√ß√£o espec√≠fica).

Deduplica√ß√£o (detectar repeti√ß√£o de conte√∫do/situa√ß√µes).

Clustering (t√≥picos de insatisfa√ß√£o).

Detec√ß√£o de ‚Äúcasos similares resolvidos‚Äù p/ sugerir respostas.

se quiser, te envio na sequ√™ncia:

requirements.txt do backend (Django, DRF, Channels, Celery, psycopg2, websockets),

migrations iniciais (incluindo CREATE EXTENSION vector),

um seed com PromptTemplate default e um comando management replay_experiment pra rodar backfill por janela.

quer que eu j√° te entregue esses tr√™s arquivos prontos?

Voc√™ disse:
ajuste o prompt e me passe novamente
O ChatGPT disse:

perfeito ‚Äî abaixo est√° o PROMPT MESTRE AJUSTADO para o seu stack final: Django + DRF + Channels + Celery (backend), React + Vite + Tailwind + shadcn (frontend), PostgreSQL + pgvector (Railway), ingest√£o Evolution API, IA via MCP (n8n/HTTP), multi-tenant SaaS, billing mensal e experimentos de prompt.
Cole esse prompt no Cursor (modo Architect/Initialize Project). Ele j√° pede scaffolding, modelos, endpoints, jobs e deploy.

PROMPT MESTRE ‚Äî EVO SENSE (Django + React + Postgres + pgvector)
# üß© EVO SENSE ‚Äî PROJECT INITIALIZATION PROMPT (Django + React)

Voc√™ √© um **arquiteto fullstack s√™nior**. Gere um **monorepo produ√ß√£o-ready** para um SaaS multi-tenant chamado **EvoSense**, com:

- **Backend:** Django 5, Django REST Framework, Django Channels (WebSockets), Celery (jobs), Python 3.11+
- **Frontend:** React + TypeScript + Vite + TailwindCSS + shadcn/ui
- **Banco:** PostgreSQL (Railway) com **pgvector** para busca sem√¢ntica
- **Infra:** Docker + Railway
- **Mensageria:** Evolution API via WebSocket (ingest√£o de mensagens WhatsApp)
- **IA:** via MCP (n8n HTTP webhook) **ou** HTTP direto para modelo local (Qwen/Ollama)
- **Multi-tenancy:** por linha (`tenant_id`) + RBAC (admin/operator)
- **Billing:** Stripe mensal (ciclos de 30 dias), planos por quantidade de n√∫meros conectados
- **Experimentos:** versionamento de prompts e *shadow inference* (champion/challenger)
- **Observabilidade:** logs estruturados e m√©tricas b√°sicas

## üéØ Objetivos
1) **Ingest√£o**: consumir mensagens da Evolution API (por tenant/connection), persistir, enviar √† IA e armazenar resultados.
2) **IA**: classificar `sentiment` (-1..1), `emotion`, `satisfaction` (0..100), `tone`, `summary`.
3) **Busca sem√¢ntica**: indexar embeddings em `pgvector` e expor endpoint de semantic search.
4) **Multi-tenant**: isolar dados por tenant; impor limites por plano (n¬∫ de connections, reten√ß√£o, exports/dia).
5) **Billing**: Stripe (planos Starter/Pro/Scale/Enterprise), cron di√°rio, suspens√£o ao falhar cobran√ßa.
6) **Experimentos**: registrar `prompt_version`, rodar replay/backfill, shadow online e m√©tricas comparativas.
7) **Frontend**: autentica√ß√£o, dashboard de KPIs, lista de conversas, detalhe, conex√µes, billing, experimentos; realtime via Channels.

## üß± Estrutura esperada do monorepo
```
/evosense
  /backend
    manage.py
    evosense/settings.py
    evosense/asgi.py
    evosense/celery.py
    /apps
      /tenancy
      /authn
      /connections
      /messages
      /ai
      /billing
      /experiments
    /ingestion
      evolution_ws.py
    /common
      utils.py
      permissions.py
    requirements.txt
    Dockerfile
  /frontend
    src/...
    index.html
    package.json
    vite.config.ts
    Dockerfile
  /docs
    ARCHITECTURE.md
    DB_SCHEMA.md
    DEPLOYMENT.md
  /rules.md
  docker-compose.yml
  README.md
```

## üîê Autentica√ß√£o & Multi-tenant
- Custom User (extens√£o de AbstractUser) com `tenant` (FK) e `role` (`admin`/`operator`).
- Todo endpoint DRF filtra por `request.user.tenant_id`. Forne√ßa um `BaseTenantViewSet`/`TenantFilterBackend`.
- Permiss√µes: `IsAuthenticated` + `IsTenantMember` + `RoleRequired`.

## üóÉÔ∏è Modelos (Django ORM)
Crie modelos e migrations:

**tenancy.Tenant**
- `id (UUID, PK)`, `name`, `plan (starter|pro|scale|enterprise)`, `next_billing_date (date)`, `status (active|suspended)`, `created_at`

**authn.User** (extends AbstractUser)
- `tenant (FK)`, `role (admin|operator)`

**connections.EvolutionConnection**
- `tenant (FK)`, `name`, `evo_ws_url`, `evo_token` (armazenar de forma segura), `is_active`, `created_at`

**messages.Message**
- `tenant (FK)`, `connection (FK)`, `chat_id`, `sender` (hash do n√∫mero), `text`, `created_at`
- resultados IA: `sentiment (float -1..1)`, `emotion (str)`, `satisfaction (int 0..100)`, `tone (str)`, `summary (str)`
- `embedding` (coluna pgvector) ‚Äî **implementar via SQL raw helper** (ver DAO)
- √≠ndices: `created_at`, `chat_id` e GIN em `text`

**experiments.PromptTemplate**
- `version (unique)`, `body (Text)`, `created_at`

**experiments.Inference**
- `tenant (FK)`, `message (FK)`, `model_name`, `prompt_version`, `template_hash`, `latency_ms`, `sentiment`, `emotion`, `satisfaction`, `is_shadow (bool)`, `run_id`, `created_at`

**billing.PaymentAccount**
- `tenant (FK)`, `stripe_customer_id`, `status (active|expired|pending)`

## üóÑÔ∏è pgvector
- Migration para `CREATE EXTENSION IF NOT EXISTS vector;`
- Adicionar coluna `embedding vector(768)` em `messages_message` (ajuste dimens√µes conforme seu encoder).
- Criar √≠ndice IVFFLAT: `USING ivfflat (embedding vector_cosine) WITH (lists = 100)`.
- DAO helpers:
  - `write_embedding(message_id, list[float])` ‚Üí SQL `UPDATE ... SET embedding = %s::vector`
  - `semantic_search(tenant_id, query_emb, limit)` ‚Üí `ORDER BY embedding <-> %s::vector`

## üì° Ingest√£o Evolution (WebSocket)
- `ingestion/evolution_ws.py` com asyncio + websockets.
- Iniciar um listener por `EvolutionConnection` ativa (multi-tenant).
- Ao receber `type=message`:
  1) persistir `Message`
  2) **Celery task** `analyze_message_async(tenant_id, message_id, prompt_version=None, is_shadow=False, run_id='prod')`

## üß† IA via MCP (n8n HTTP) / HTTP local
- Configurar **N8N_AI_WEBHOOK** no `.env`.
- `apps/ai/tasks.py`:
  - montar payload:
    ```json
    {
      "tenant_id": "...",
      "message": "texto",
      "context": { "chat_id": "...", "sender": "..." },
      "prompt_version": "<vers√£o ativa ou fornecida>"
    }
    ```
  - timeout + retries (3x) com backoff.
  - parse do JSON de resposta:
    ```json
    { "sentiment": 0.72, "emotion": "positivo", "satisfaction": 85, "tone": "...", "summary": "..." }
    ```
  - salvar no `Message` (se n√£o shadow), registrar em `Inference`, gerar embedding e `write_embedding`.
- Expor tamb√©m `/api/ai/analyze` (admin) p/ reprocessar uma mensagem.

## üîÅ Experimentos (replay & shadow)
- Endpoint admin `POST /api/experiments/replay` com `{ tenant_id, start, end, prompt_version, run_id }` ‚Üí Celery `replay_window(...)` chamando `analyze_message_async(..., is_shadow=True)`.
- Em produ√ß√£o: `champion/challenger` (90/10) controlado por tabela `PromptTemplate` e feature flag:
  - O *campe√£o* preenche `Message`.
  - O *challenger* grava s√≥ em `Inference`.

## üßæ Billing (Stripe)
- `billing.service`: criar/associar `stripe_customer_id`.
- Webhook Stripe: eventos de pagamento (invoice.paid/failed).
- Cron di√°rio (Celery beat ou `cron` do sistema) para:
  - checar `next_billing_date` e criar cobran√ßa
  - se falhar, `status = suspended` no tenant
- Planos e limites:
  - Starter: 1 n√∫mero, retain 30d
  - Pro: 3 n√∫meros, retain 180d
  - Scale: 6 n√∫meros, retain 365d
  - Enterprise: custom
- Middleware/Service de verifica√ß√£o de limites (ex.: `connections.count <= plan_limit`).

## üåê API (DRF) ‚Äî endpoints m√≠nimos
- `POST /api/auth/login` | `GET /api/me`
- `GET /api/tenants/:id/metrics` (m√©dias, volumes, p95 lat√™ncia)
- `GET /api/messages?chat_id=&q=&page=...` (p√°gina√ß√£o + FTS)
- `POST /api/messages/semantic-search` { query } ‚Üí top-K via pgvector
- `GET/POST /api/connections`
- `GET/POST /api/prompts` (registrar novas vers√µes)
- `POST /api/experiments/replay` (admin)
- `POST /api/ai/analyze` (admin)
- `POST /api/webhooks/stripe`
- (Opcional) `POST /api/webhooks/evolution` como fallback HTTP

## üîå WebSockets (Channels)
- Rota: `ws/tenant/<tenant_id>/`
- Consumer agrupa por `tenant_<id>`.
- Ap√≥s an√°lise IA, emitir evento `message_analyzed` com `{ message_id, sentiment, satisfaction, emotion, tone }`.

## üß∞ Frontend (React)
- P√°ginas: Login, Dashboard, Conversas, Detalhe, Conex√µes, Experimentos, Billing
- Tailwind + shadcn para UI; Zustand para estado global
- Conectar WS: `ws://<backend>/ws/tenant/<tenant_id>/`
- Semantic search: chamar `/api/messages/semantic-search`
- Billing: p√°gina com plano atual, pr√≥ximas cobran√ßas, upgrade (Stripe Checkout/Portal)

## ‚öôÔ∏è Configura√ß√£o & Deploy (Railway)
- `.env.example`:
  ```
  DJANGO_SECRET_KEY=
  DATABASE_URL=postgresql://user:pass@host:port/db
  REDIS_URL=redis://host:port/0
  STRIPE_SECRET_KEY=
  N8N_AI_WEBHOOK=https://<n8n>/webhook/ai-analysis
  EVO_BASE_URL=
  ALLOWED_HOSTS=*
  ```
- Railway Postgres: rodar `CREATE EXTENSION IF NOT EXISTS vector;` uma √∫nica vez.
- Backend start: `python manage.py migrate && daphne -b 0.0.0.0 -p 8000 evosense.asgi:application`
- Celery: `celery -A evosense worker -l info` e (se usar beat) `celery -A evosense beat -l info`
- Frontend: `npm run build && npm run preview -- --host 0.0.0.0 --port 5173`

## üß™ Qualidade & Observabilidade
- Linters (ruff/flake8), Black, isort.
- Logs estruturados (json) com request-id/tenant-id.
- Healthchecks: `/health` backend; WS ping/pong.
- Testes: unit de services/DAO e e2e b√°sicos de API.

## üìÑ Docs & Rules (gerar arquivos)
- `rules.md`: conven√ß√µes de c√≥digo, m√≥dulos, seguran√ßa, limites de plano, versionamento de prompt, pol√≠ticas de PII.
- `docs/ARCHITECTURE.md`: diagrama, fluxos ingest√£o‚ÜíIA‚Üípersist√™ncia‚ÜíWS.
- `docs/DB_SCHEMA.md`: tabelas, chaves, √≠ndices (incluindo pgvector).
- `docs/DEPLOYMENT.md`: Railway (servi√ßos, envs, comandos), migra√ß√µes e inicializa√ß√£o.

## ‚úÖ Entreg√°veis
1) Monorepo com **backend e frontend** prontos para build.
2) Migrations incluindo **pgvector**.
3) Ingestion WebSocket funcional (arquivo `ingestion/evolution_ws.py`) e Celery tasks de an√°lise.
4) DAO pgvector (write/search).
5) Endpoints DRF e Consumer Channels m√≠nimos.
6) P√°ginas React e hook WS.
7) Scripts de deploy Railway.
8) Seeds opcionais (um `PromptTemplate` default e cria√ß√£o de planos).

> Objetivo: **c√≥digo pronto para subir no Railway**, com ingest√£o Evolution, IA via MCP/HTTP, busca sem√¢ntica, multi-tenant, billing e experimentos de prompt.


se quiser, adapto esse prompt para ‚Äúcodegen direto‚Äù (o Cursor j√° sair escrevendo os arquivos), ou te entrego os arquivos iniciais (rules.md, docs/*.md, requirements.txt, docker-compose.yml) prontos pra colar. Quer que eu gere esses arquivos agora?

Voc√™ disse:
pode adpta e gera o rules.mf o restante √© com ele
O ChatGPT disse:

Perfeito ‚Äî aqui est√° o arquivo rules.md totalmente ajustado ao stack que voc√™ definiu:
Django + DRF + Channels + Celery + React + PostgreSQL + pgvector + Railway + Evolution API + MCP (n8n).
Esse arquivo serve como guia t√©cnico, estilo de c√≥digo e pol√≠tica de arquitetura para o Cursor seguir.

# üö¶ EVO SENSE ‚Äî RULES OF DEVELOPMENT

## üß≠ Vis√£o Geral
EvoSense √© uma plataforma **SaaS multi-tenant** para an√°lise de sentimento e satisfa√ß√£o de clientes em conversas do WhatsApp (Evolution API).  
Stack principal:
- **Backend:** Django 5 + DRF + Channels + Celery
- **Frontend:** React + TypeScript + Vite + Tailwind + shadcn/ui
- **Banco:** PostgreSQL + pgvector
- **Infra:** Docker + Railway
- **IA:** via MCP (n8n HTTP) ou modelo local (Qwen/Ollama)
- **Billing:** Stripe (30 dias)
- **Realtime:** Django Channels (WebSocket)
- **Experimentos:** versionamento de prompts e shadow inference

---

## üß± Arquitetura
- Estrutura de monorepo:


/backend
/apps
/tenancy
/authn
/connections
/messages
/ai
/billing
/experiments
/ingestion (Evolution WebSocket)
/common
/frontend

- Banco: **PostgreSQL 15+** (Railway)  
- Extens√£o `pgvector` habilitada: `CREATE EXTENSION IF NOT EXISTS vector;`
- Processos ass√≠ncronos com **Celery + Redis**.
- Eventos em tempo real via **Channels (Redis layer)**.
- Deploy via **Railway Docker service**.

---

## üîê Multi-tenancy e Seguran√ßa
- Cada modelo tem `tenant_id` (FK ‚Üí Tenant).
- `User` customizado (extends `AbstractUser`) com `tenant` e `role (admin/operator)`.
- Todas as queries filtram por `tenant_id`.
- Dados sens√≠veis (tokens Evolution, Stripe) s√£o criptografados ou armazenados em cofres.
- JWT/Session Auth padr√£o DRF.
- Sanitiza√ß√£o de mensagens (regex para PII: CPF, email, cart√£o).
- WebSockets segregados por tenant: `/ws/tenant/<tenant_id>/`.

---

## üì° Ingest√£o (Evolution API)
- Cada conex√£o ativa gera um listener WebSocket (`evo_ws_url`, `evo_token`).
- Ao receber uma mensagem:
1. Cria registro em `messages_message`.
2. Enfileira task Celery `analyze_message_async`.
3. Ap√≥s an√°lise IA, envia evento `message_analyzed` via Channels.

---

## üß† IA (MCP / Qwen / Ollama)
- Webhook HTTP configur√°vel (`N8N_AI_WEBHOOK`).
- Payload:
```json
{
  "tenant_id": "...",
  "message": "...",
  "context": { "chat_id": "...", "sender": "..." },
  "prompt_version": "p_v1_base"
}


Retorno esperado:

{
  "sentiment": 0.72,
  "emotion": "positivo",
  "satisfaction": 85,
  "tone": "cordial",
  "summary": "Cliente satisfeito com a resposta."
}


Prompt versionado em PromptTemplate.

Experimentos de shadow inference (champion/challenger).

Embeddings gerados localmente (Qwen/Ollama) e armazenados em pgvector.

üóÉÔ∏è Banco de Dados

Tabelas principais:

tenancy_tenant

authn_user

connections_evolutionconnection

messages_message

coluna embedding vector(768)

experiments_prompttemplate

experiments_inference

billing_paymentaccount

√çndices

GIN em text (full-text).

IVFFLAT em embedding vector_cosine.

Index em created_at e chat_id.

üß© IA Experiments

PromptTemplate define corpo do prompt e version.

Inference armazena resultados, lat√™ncia e run_id.

Backfill (replay_window) reprocessa mensagens hist√≥ricas com prompt novo.

Shadow inference: roda prompt challenger em paralelo (10% tr√°fego).

üí≥ Billing

Stripe SDK + webhooks.

PaymentAccount armazena stripe_customer_id e status.

Cron di√°rio:

Cobra tenants com next_billing_date <= hoje.

Atualiza status (active, suspended).

Planos:

Plano	Conex√µes	Reten√ß√£o	Pre√ßo (BRL)
Starter	1	30 dias	199
Pro	3	180 dias	499
Scale	6	365 dias	999
Enterprise	custom	2 anos	sob contrato
üîå API (DRF)

Endpoints obrigat√≥rios:

/api/auth/login, /api/me

/api/messages (listagem, filtros, full-text)

/api/messages/semantic-search (pgvector)

/api/connections (CRUD)

/api/prompts (vers√µes)

/api/experiments/replay

/api/ai/analyze

/api/tenants/:id/metrics

/api/webhooks/stripe

/health

‚öôÔ∏è Celery

Worker + Beat habilitados.

Filas:

default ‚Äî tasks de IA

billing ‚Äî cobran√ßas

experiments ‚Äî replays

Retries autom√°ticos e logs estruturados (tenant_id, task_id, latency_ms).

üåê WebSockets (Channels)

Consumer principal: TenantConsumer

Grupo: tenant_<id>

Eventos:

message_analyzed

connection_status

Broadcast de mensagens IA para frontend em tempo real.

üíª Frontend (React)

Login (JWT) + Painel principal.

Dashboard de KPIs:

m√©dia de satisfa√ß√£o, % positivas, mensagens/dia.

Conversas (lista + detalhe).

Busca sem√¢ntica (input ‚Üí /api/messages/semantic-search).

Aba de conex√µes Evolution.

Aba de experimentos (prompts + comparativos).

Billing (plano atual, cobran√ßa Stripe).

WebSocket conectado via ws://<backend>/ws/tenant/<tenant_id>/.

üß∞ Boas pr√°ticas

C√≥digo Python: formatar com Black + Ruff.

C√≥digo JS/TS: ESLint + Prettier.

Nomenclatura consistente (snake_case backend, camelCase frontend).

M√≥dulos separados por dom√≠nio (clean architecture).

Padr√£o de commits: Conventional Commits.

Testes unit√°rios e integra√ß√£o (pytest + DRF test client).

üìÑ Seguran√ßa

Criptografia de tokens Evolution e Stripe.

Sanitiza√ß√£o de logs (nunca armazenar texto sens√≠vel completo).

Rate limiting nos endpoints p√∫blicos.

CORS configurado apenas para dom√≠nios do cliente.

HTTPS obrigat√≥rio em produ√ß√£o.

‚òÅÔ∏è Railway Deploy

Servi√ßos:

backend: Django + Channels + Celery worker.

redis: Redis 7.x.

postgres: Railway Postgres (extens√£o vector).

frontend: React build.

Comandos:

python manage.py migrate
celery -A evosense worker -l info
daphne -b 0.0.0.0 -p 8000 evosense.asgi:application
npm run build && npm run preview

üîé Observabilidade

Logs estruturados JSON (pino ou loguru).

M√©tricas b√°sicas: requisi√ß√µes, lat√™ncia IA, volume de mensagens.

Endpoint /health e /metrics (Prometheus-style).

üßæ Versionamento de Prompt

Cada prompt tem version, hash e body.

Toda infer√™ncia armazena qual vers√£o foi usada.

Permitir replay hist√≥rico com novas vers√µes.

Guardar dataset de treino interno (text, sentiment, emotion, satisfaction) para futuras calibra√ß√µes.

üß† Estrat√©gia de IA local

Modelo: Qwen (rodando on-prem ou Ollama).

Custo por mensagem: ~zero.

Quantiza√ß√£o INT4/INT8 + batching.

Embeddings: Qwen-mini ou Ollama embedding model.

Reposit√≥rio de experimentos versionado (prompt_vN).

‚úÖ Regras finais

Nenhum dado cru de cliente fora do banco.

Cada Tenant isolado em queries e permiss√µes.

Testar todos os endpoints cr√≠ticos com JWT.

IA deve sempre retornar JSON estrito e validado.

pgvector usado apenas para busca, n√£o para storage prim√°rio.

S√≥ salvar texto bruto de mensagens se plano permitir.---
alwaysApply: true
---
